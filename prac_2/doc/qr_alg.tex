\section{Transformacja Householdera}

\subsection{Podstawy teoretyczne}

Transformacja Householdera [ \worldflag[length=12px, width=7px]{GB}: Householder transformation ] to liniowe przekształcenie poprzez odbicie punktu wokół płaszczyzny, lub hiperpłaszczyzny, która zawiera początek układu współrzędnych. Płaszczyzna wokół której obracamy jest zdefiniowana przez jednostkowy wektor $u$ do niej normalny, a więc odbicie względem niej to $x$ pomniejszony o dwa rzuty na $u$:
$$x'=x-2u\langle x,u\rangle=x-2u(u^*x)$$
co dla przestrzeni rzeczywistej wynosi
$$x'=x-2u(u^Tx).$$
Macierz tego odbicia to
$$P=I-2uu^*$$
i jest ona Hermitowska:
$$P^*=(I-2uu^*)^*=I^*-(2uu^*)^*=I-2(uu^*)^*=I-2(u^*)^*u^*=I-2uu^*=P$$
oraz unitarna (czyli $P^*P=PP=I$):
\begin{align*}
    P^*P&=P^2=(I-2uu^*)^2=I-4uu^*+4(uu^*)^2=\\
    &=I-4uu^*+4u(u^*u)u^*=I-4uu^*+4u\langle u,u\rangle u^*=\\
    &=I-4uu^*+4uu^*=I
\end{align*}
a więc w przypadku rzeczywistym dostajemy macierz symetryczną i ortogonalną, czyli taką jakiej szukamy.

Niech teraz $A$ będzie macierzą $m\times m$, której formę $QR$ chcemy znaleźć, a $a_1,...,a_m$ będą wektorami odpowiadającymi jej kolumnom. Dalej, niech $e_1,...,e_m$ będą wektorami ze standardowej bazy przestrzeni $\R^m$ i ustalmy
$$v=a_1-\|a_1\|e_1$$
$$u={v\over\|v\|}.$$
Wektor $u$ jest jednostkowym wektorem pewnej płaszczyzny przechodzącej przez początek układu współrzędnych, możemy więc dla niego znaleźć macierz Householdera
$$P'_1=I-2uu^*.$$
Zauważmy, że
$$P'_1a_1=\begin{pmatrix}\|a_1\|\\0\\0\\...\\0\end{pmatrix}$$
czyli zaczynamy tworzyć macierz górnotrójkątną. Proces transformacji Householdera możemy powtórzyć dla macierzy $P_1A$ bez pierwszej kolumny i wiersza, co da nam macierz $P'_2$ która dla $P'_2a_2$ daje wektor niezerowy tylko na pierwszej współrzędnej. Jednak $P'_2$ jest $(m-1)\times(m-1)$, więc musimy ją rozciągnąć, chociażby dodając identyczność w lewym górnym rogu. Rozciągając tę procedurę na przypadek ogólny, mamy
$$P_k=\begin{pmatrix}
    I_{k-1}&*\\
    0&P'_k
\end{pmatrix}$$
gdzie $I_{k-1}$ to identyczność ale na $\R^{k-1}$. 

Szukana przez nas macierz górnotrójkątna ma zatem postać
$$R=P_m...P_1A$$
natomiast szukana macierz ortogonalna to
$$Q=(P_m...P_1)^{-1}=P_1^{-1}...P_m^{-1}=P_1...P_m$$
z faktu, że każda z macierzy $P_k$ jest unitarna i hermitowska.

Dla polepszenia wyników algorytmu definicja wektora $v$ musi brać pod uwagę znak lewego górnego rogu macierzy (minora) którą będziemy poddawać transformacji Householdera. Chcemy zawsze mnożyć normę $a_1$ przez znak przeciwny do wspomnianego elementu macierzy.

\subsection{Wyniki}

W ~Tabeli~\ref{house:error} umieszczony został rząd wielkości błędu metody w zależności od wielkości macierzy $A$ oraz precyzji arytmetyki. Różnica między precyzja obliczeń dla różnych wielkości macierzy jest w okolicach $3$ i zachowuje się miedzy różnymi precyzjami, co jest wynikiem napawającym nadzieją. Z ~Tabeli~\ref{house:2matrix} widzimy też, że otrzymana przez nas macierz $Q$ jest bardzo bliska bycia macierzą ortogonalną, przynajmniej pod względem normy, to znaczy 
$$\|Q\|=\sup\limits_{\|x\|\leq1}{\|Qx\|\over\|x\|}$$ 
jest niewiele większe od zera. 

Co ciekawe, liczba cyfr znaczących różnicy między otrzymanym przez nas rozwiązaniem równania a rozwiązaniem poprawnym (Tabela~\ref{house:error}) oraz norma macierzy będących przekształceniem $A=QR$ (Tabele~\ref{house:1matrix},\ref{house:2matrix},\ref{house:3matrix})  jest na tym samym poziomie precyzji.

\begin{figure}[!h]\centering
\begin{tabularx}{100mm}{| >{\hsize=.20\hsize}X | >{\hsize=.3\hsize}X | >{\hsize=.3\hsize}X | >{\hsize=.25\hsize}X |}
    \hline

    \raggedleft Precyzja & $20\times20$ & $100\times100$ & $400\times400$\\

    \hline

    \raggedleft68 & 42.66 & 39.46 & 36.86\\

    \hline

    \raggedleft419 & 286.19 & 282.58 & 280.144\\

    \hline

    \raggedleft2005 & 1476.08 & 1473.03 & 1470.28\\
    \hline

\end{tabularx}
\renewcommand{\figurename}{Tablusia}
\caption{Rząd wielkości błędu metody transformacji Householdera.}
\label{house:error}
\end{figure}

\begin{figure}[!h]\centering
\begin{tabularx}{100mm}{| >{\hsize=.20\hsize}X | >{\hsize=.3\hsize}X | >{\hsize=.3\hsize}X | >{\hsize=.25\hsize}X |}
    \hline

    \raggedleft Precyzja & $20\times20$ & $100\times100$ & $400\times400$\\

    \hline

    \raggedleft68 & 41.96 & 40.68 & 38.67\\

    \hline

    \raggedleft419 & 286.50 & 284.19 & 282.22\\

    \hline

    \raggedleft2005 & 1476.00 & 1471.28 & 1470.08\\
    \hline

\end{tabularx}
\renewcommand{\figurename}{Tabelka}
\caption{Rząd wielkości normy macierzy $A-QR$.}
\label{house:1matrix}
\end{figure}

\begin{figure}[!h]\centering
\begin{tabularx}{100mm}{| >{\hsize=.20\hsize}X | >{\hsize=.3\hsize}X | >{\hsize=.3\hsize}X | >{\hsize=.25\hsize}X |}
    \hline

    \raggedleft Precyzja & $20\times20$ & $100\times100$ & $400\times400$\\

    \hline

    \raggedleft68 & 43.48 & 42.18 & 40.85\\

    \hline

    \raggedleft419 & 286.91 & 285.47 & 284.14\\

    \hline

    \raggedleft2005 & 1477.15 & 1475.61 & 1474.25\\
    \hline

\end{tabularx}
\renewcommand{\figurename}{Tabelka}
\caption{Rząd wielkości normy macierzy $Q^TQ-I$.}
\label{house:2matrix}
\end{figure}

\begin{figure}[!h]\centering
\begin{tabularx}{100mm}{| >{\hsize=.20\hsize}X | >{\hsize=.3\hsize}X | >{\hsize=.3\hsize}X | >{\hsize=.25\hsize}X |}
    \hline

    \raggedleft Precyzja & $20\times20$ & $100\times100$ & $400\times400$\\

    \hline

    \raggedleft68 & 43.20 & 40.97 & 38.91\\

    \hline

    \raggedleft419 & 286.59 & 284.3 & 282.25\\

    \hline

    \raggedleft2005 & 1476.83 & 1474.34 & 1472.37\\
    \hline

\end{tabularx}
\renewcommand{\figurename}{Tabelka}
\caption{Rząd wielkości normy macierzy $Q^TA-R$.}
\label{house:3matrix}
\end{figure}

\subsection{Złożoność obliczeniowa}


W naszej implementacji najpierw wykonujemy n iteracji zewnętrznej pętli. Wewnątrz której mamy pętle po kolumnach oraz pętle po wierszach.

W każdym kroku obu tych pętli wykonujemy stałą liczbę następujących operacji: mnożenie wektora przez skalar, dodawania/odejmowanie wektorów, mnożenie wektora przez wektor o takim rozmiarze ale, który został transponowany.
Wszystkie te operacje mają złożoność $O(n)$. I jako że jest ich stała liczba, to każda iteracja tych pętli ma złożoność $O(n)$

Żeby użyć tego algorytmu do rozwiązania układu równań, trzeba potem użyć algorytmu Backward substitution, ma on złożoność $O(n^2)$.

Czyli złożoność całego algorytmu to
\[
\sum_{i=1}^{n}(\sum^n_{j=i} O(N) + \sum^n_{j=i} O(N) ) + O(n^2) = O(n^3)   
\] 

